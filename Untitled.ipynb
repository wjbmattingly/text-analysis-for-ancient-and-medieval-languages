{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sufficient-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifth-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "spread-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gernating rules\n",
    "def generate_ruler(patterns, name):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "    ruler.add_patterns(patterns)\n",
    "    ruler.to_disk(f\"models/{name}_ent_ruler/entity_ruler/patterns.jsonl\") \n",
    "    nlp.to_disk(f\"models/{name}_ent_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(file, type):\n",
    "    data = load_data(file)\n",
    "    patterns = []\n",
    "    for item in data:\n",
    "        pattern = {\n",
    "                    \"label\": type,\n",
    "                    \"pattern\": item\n",
    "                    }\n",
    "        patterns.append(pattern)\n",
    "    return (patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qualified-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ent_ruler(ruler, corpus):\n",
    "    nlp = spacy.load(ruler)\n",
    "    with open (corpus, \"r\", encoding=\"utf-8\") as f:\n",
    "        corpus = f.read()\n",
    "    with open (\"temp/results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        doc = nlp(corpus)\n",
    "        for ent in doc.ents:\n",
    "            f.write(f\"{ent.text}, {ent.label_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "contrary-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_set(corpus, ent_ruler_model, output_file, prodigy=False):\n",
    "    nlp=spacy.load(ent_ruler_model)\n",
    "    TRAIN_DATA = []\n",
    "    with open (corpus, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "        segments = data.split(\"\\n\")\n",
    "        for segment in segments:\n",
    "            segment = segment.strip()\n",
    "            doc = nlp(segment)\n",
    "            entities = []\n",
    "            for ent in doc.ents:\n",
    "                if prodigy==True:\n",
    "                    entities.append({\"start\":ent.start_char, \"end\": ent.end_char,  \"label\": ent.label_, \"text\": ent.text})\n",
    "                    pass\n",
    "                else:\n",
    "                    entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "            if len(entities) > 0:\n",
    "                if prodigy==True:\n",
    "                    TRAIN_DATA.append({\"text\": segment, \"spans\": entities})\n",
    "                else:\n",
    "                    TRAIN_DATA.append([segment, {\"entities\": entities}])\n",
    "    print (len(TRAIN_DATA))\n",
    "    with open (output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(TRAIN_DATA, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cathedral-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_patterns = create_training_data(\"latin_data/all_names_declined.json\", \"PERSON\")\n",
    "groups_patterns = create_training_data(\"latin_data/groups_declined.json\", \"GROUP\")\n",
    "places_patterns = create_training_data(\"latin_data/places_declined.json\", \"LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "appointed-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patterns = person_patterns+groups_patterns+places_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ruler(all_patterns, \"latin_loc_per_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "proper-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ent_ruler(\"models/latin_loc_per_group_ent_ruler\", \"latin_data/corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "desperate-renewal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n"
     ]
    }
   ],
   "source": [
    "create_training_set(\"latin_data/corpus.txt\", \"models/latin_loc_per_group_ent_ruler\", \"training_data/training_set_spacy.json\", prodigy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adapted-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "daily-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = load_data(\"training_data/training_set_spacy.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "rental-barrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[1] Gallia est omnis divisa in partes tres, quarum unam incolunt Belgae, aliam Aquitani, tertiam qui ipsorum lingua Celtae, nostra Galli appellantur. Hi omnes lingua, institutis, legibus inter se differunt. Gallos ab Aquitanis Garumna flumen, a Belgis Matrona et Sequana dividit. Horum omnium fortissimi sunt Belgae, propterea quod a cultu atque humanitate provinciae longissime absunt, minimeque ad eos mercatores saepe commeant atque ea quae ad effeminandos animos pertinent important, proximique sunt Germanis, qui trans Rhenum incolunt, quibuscum continenter bellum gerunt. Qua de causa Helvetii quoque reliquos Gallos virtute praecedunt, quod fere cotidianis proeliis cum Germanis contendunt, cum aut suis finibus eos prohibent aut ipsi in eorum finibus bellum gerunt. Eorum una, pars, quam Gallos obtinere dictum est, initium capit a flumine Rhodano, continetur Garumna flumine, Oceano, finibus Belgarum, attingit etiam ab Sequanis et Helvetiis flumen Rhenum, vergit ad septentriones. Belgae ab extremis Galliae finibus oriuntur, pertinent ad inferiorem partem fluminis Rheni, spectant in septentrionem et orientem solem. Aquitania a Garumna flumine ad Pyrenaeos montes et eam partem Oceani quae est ad Hispaniam pertinet; spectat inter occasum solis et septentriones.', {'entities': [[4, 10, 'LOCATION'], [65, 71, 'GROUP'], [79, 87, 'GROUP'], [116, 122, 'GROUP'], [131, 136, 'GROUP'], [207, 213, 'GROUP'], [217, 226, 'GROUP'], [245, 251, 'GROUP'], [309, 315, 'LOCATION'], [591, 599, 'GROUP'], [616, 622, 'GROUP'], [796, 802, 'GROUP'], [848, 855, 'LOCATION'], [885, 891, 'LOCATION'], [901, 909, 'GROUP'], [929, 937, 'GROUP'], [941, 950, 'GROUP'], [991, 997, 'GROUP'], [1128, 1137, 'LOCATION'], [1190, 1196, 'LOCATION'], [1209, 1218, 'LOCATION']]}]\n"
     ]
    }
   ],
   "source": [
    "print (all_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aggressive-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = all_docs[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "wicked-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_docs = all_docs[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bridal-mobility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "incorporated-marsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 609.77it/s]\n"
     ]
    }
   ],
   "source": [
    "train_db = DocBin()\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.blank(\"en\")\n",
    "for text, annot in tqdm(train_docs):\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            pass\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    train_db.add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dutch-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 188/188 [00:00<00:00, 648.33it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_db = DocBin()\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.blank(\"en\")\n",
    "for text, annot in tqdm(valid_docs):\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            pass\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    train_db.add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-lover",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "simplified-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db.to_disk(\"./training_data/train_hs.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "laughing-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_db.to_disk(\"./training_data/valid_hs.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "green-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-01 11:43:01.032686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acoustic-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     81.36    0.00    0.00    0.00    0.00\n",
      "  0     200          9.41   1744.06    0.00    0.00    0.00    0.00\n",
      "  1     400         24.45    481.48    0.00    0.00    0.00    0.00\n",
      "  1     600         41.73    239.30    0.00    0.00    0.00    0.00\n",
      "  2     800         74.30    178.93    0.00    0.00    0.00    0.00\n",
      "  2    1000         58.22    115.73    0.00    0.00    0.00    0.00\n",
      "  3    1200         72.91    110.32    0.00    0.00    0.00    0.00\n",
      "  4    1400         99.68    140.03    0.00    0.00    0.00    0.00\n",
      "  5    1600         91.67    108.83    0.00    0.00    0.00    0.00\n",
      "[+] Saved pipeline to output directory\n",
      "output\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-01 11:44:33.292158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
      "[2021-07-01 11:44:36,020] [INFO] Set up nlp object from config\n",
      "[2021-07-01 11:44:36,020] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-07-01 11:44:36,020] [INFO] Created vocabulary\n",
      "[2021-07-01 11:44:37,555] [INFO] Added vectors: en_core_web_lg\n",
      "[2021-07-01 11:44:37,555] [INFO] Finished initializing nlp object\n",
      "[2021-07-01 11:44:39,595] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "normal-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bigger-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"latin_data/livy_01.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "italian-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "amino-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Troia LOCATION\n",
      "Troianos GROUP\n",
      "Achivos GROUP\n",
      "Paphlagonia GROUP\n",
      "Pylaemene GROUP\n",
      "Troiam GROUP\n",
      "Troia GROUP\n",
      "Veneti GROUP\n",
      "Macedoniam PERSON\n",
      "Aenea PERSON\n",
      "Troianos GROUP\n",
      "Aeneas PERSON\n",
      "Ascanium PERSON\n",
      "Rutulique GROUP\n",
      "Rutulis PERSON\n",
      "Aeneas PERSON\n",
      "Aboriginum GROUP\n",
      "Aeneas PERSON\n",
      "Numicum PERSON\n",
      "Etruscis GROUP\n",
      "Etruscis LOCATION\n",
      "Latinisque PERSON\n",
      "Silvium PERSON\n",
      "Silvium GROUP\n",
      "Prisci PERSON\n",
      "Capys GROUP\n",
      "Romulus PERSON\n",
      "Amulium GROUP\n",
      "Romani GROUP\n",
      "Romulus PERSON\n",
      "Remus GROUP\n",
      "Romulus PERSON\n",
      "Remus PERSON\n",
      "Remumque GROUP\n",
      "Romulus PERSON\n",
      "Remus PERSON\n",
      "Remo PERSON\n",
      "Remus PERSON\n",
      "Romulus PERSON\n",
      "Evandro GROUP\n",
      "Cacus PERSON\n",
      "Hercules PERSON\n",
      "Cacus PERSON\n",
      "Sibyllae PERSON\n",
      "Italiam LOCATION\n",
      "Evander PERSON\n",
      "Hercules PERSON\n",
      "Hercules PERSON\n",
      "Pinarii PERSON\n",
      "Evandro GROUP\n",
      "Romulus PERSON\n",
      "Etruscis GROUP\n",
      "Romulus PERSON\n",
      "Romulus PERSON\n",
      "Romulus PERSON\n",
      "T. PERSON\n",
      "Crustuminique PERSON\n",
      "Tatius PERSON\n",
      "Caeninum GROUP\n",
      "Romulus PERSON\n",
      "Romulus PERSON\n",
      "Romani GROUP\n",
      "Romanos GROUP\n",
      "Crustuminos GROUP\n",
      "Utroque PERSON\n",
      "Romam GROUP\n",
      "Sabini PERSON\n",
      "Sabini PERSON\n",
      "Romani GROUP\n",
      "Mettius GROUP\n",
      "Romanis GROUP\n",
      "Palati LOCATION\n",
      "Romulus PERSON\n",
      "Sabini PERSON\n",
      "Romanis GROUP\n",
      "Iovi PERSON\n",
      "Romani GROUP\n",
      "Romani GROUP\n",
      "Romulus PERSON\n",
      "Mettius GROUP\n",
      "Romanos GROUP\n",
      "Palati GROUP\n",
      "Romulus PERSON\n",
      "Mettius GROUP\n",
      "Pulsum GROUP\n",
      "Romani GROUP\n",
      "Mettius GROUP\n",
      "Romani GROUP\n",
      "Sabinae GROUP\n",
      "Romam LOCATION\n",
      "T. PERSON\n",
      "Tatio PERSON\n",
      "Laurentium GROUP\n",
      "Romam LOCATION\n",
      "Iuventute PERSON\n",
      "Romulus PERSON\n",
      "Romani GROUP\n",
      "Romulus PERSON\n",
      "Romanos GROUP\n",
      "Romam LOCATION\n",
      "Celeres PERSON\n",
      "Romulus PERSON\n",
      "Romulus PERSON\n",
      "Romanis GROUP\n",
      "Roma GROUP\n",
      "Romanis GROUP\n",
      "Romani GROUP\n",
      "Adeo GROUP\n",
      "Numae PERSON\n",
      "Samium GROUP\n",
      "Numae PERSON\n",
      "Romani GROUP\n",
      "Numae PERSON\n",
      "Romulus PERSON\n",
      "Numae PERSON\n",
      "Argiletum GROUP\n",
      "Numae PERSON\n",
      "T. PERSON\n",
      "Caesare PERSON\n",
      "Augusto PERSON\n",
      "Numae PERSON\n",
      "Marti PERSON\n",
      "Quirino GROUP\n",
      "Marti PERSON\n",
      "Marci PERSON\n",
      "Iovi PERSON\n",
      "Camenis PERSON\n",
      "Romulus PERSON\n",
      "Numae PERSON\n",
      "Tullum PERSON\n",
      "Romulus PERSON\n",
      "Romani GROUP\n",
      "Albano GROUP\n",
      "Albani GROUP\n",
      "Gaius PERSON\n",
      "Romani GROUP\n",
      "Albani LOCATION\n",
      "Troia LOCATION\n",
      "Lavinio GROUP\n",
      "Romani GROUP\n",
      "Cluilia GROUP\n",
      "Albani LOCATION\n",
      "Albani LOCATION\n",
      "Albani GROUP\n",
      "Memor PERSON\n",
      "Horatii GROUP\n",
      "Romanos GROUP\n",
      "Romanos GROUP\n",
      "Tullum PERSON\n",
      "Albani LOCATION\n",
      "Romani GROUP\n",
      "Romani GROUP\n",
      "M. PERSON\n",
      "Valerius PERSON\n",
      "Albani LOCATION\n",
      "Albani LOCATION\n",
      "Romani GROUP\n",
      "Romani GROUP\n",
      "Romani GROUP\n",
      "Romam LOCATION\n",
      "Duumuiros PERSON\n",
      "Horatio PERSON\n",
      "P. PERSON\n",
      "Horatio PERSON\n",
      "Fidenae GROUP\n",
      "Fidenatium GROUP\n",
      "Romanis GROUP\n",
      "Fidenatium GROUP\n",
      "Romanorum GROUP\n",
      "Albani LOCATION\n",
      "Fidenatium GROUP\n",
      "Romani GROUP\n",
      "Fidenatium GROUP\n",
      "Romanis GROUP\n",
      "Romani GROUP\n",
      "Albani LOCATION\n",
      "Mettius GROUP\n",
      "Mettius GROUP\n",
      "Mettius GROUP\n",
      "Romani GROUP\n",
      "Albani GROUP\n",
      "Romam LOCATION\n",
      "Romanos GROUP\n",
      "Romam LOCATION\n",
      "Roma LOCATION\n",
      "Quinctios PERSON\n",
      "Geganios GROUP\n",
      "Romanos GROUP\n",
      "Sabini PERSON\n",
      "Sabini PERSON\n",
      "Albani GROUP\n",
      "Sabinum PERSON\n",
      "Malitiosam PERSON\n",
      "Albani LOCATION\n",
      "Romanis GROUP\n",
      "Numae PERSON\n",
      "Iovi PERSON\n",
      "Numae PERSON\n",
      "Ancus GROUP\n",
      "Romanis GROUP\n",
      "Numae PERSON\n",
      "Romuli GROUP\n",
      "Numae PERSON\n",
      "Romani GROUP\n",
      "Quirine PERSON\n",
      "Romam LOCATION\n",
      "Romani GROUP\n",
      "Prisci PERSON\n",
      "Romani GROUP\n",
      "Ancus GROUP\n",
      "Romam LOCATION\n",
      "Romanorum GROUP\n",
      "Sabini PERSON\n",
      "Caelium GROUP\n",
      "Albani LOCATION\n",
      "Ficanaque GROUP\n",
      "Prisci PERSON\n",
      "Romanis GROUP\n",
      "Romanis GROUP\n",
      "Ancus GROUP\n",
      "Romam LOCATION\n",
      "Murciae GROUP\n",
      "Tiberi GROUP\n",
      "Silva PERSON\n",
      "Romam GROUP\n",
      "Etruscis LOCATION\n",
      "Lucumonem PERSON\n",
      "Roma PERSON\n",
      "Sabinum PERSON\n",
      "Sabina PERSON\n",
      "Numae PERSON\n",
      "Romam LOCATION\n",
      "L. PERSON\n",
      "Romanis GROUP\n",
      "Ancus GROUP\n",
      "Romam LOCATION\n",
      "Romanos GROUP\n",
      "Romani GROUP\n",
      "Sabinum PERSON\n",
      "Romanis GROUP\n",
      "Ramnes GROUP\n",
      "Romulus GROUP\n",
      "Romulus PERSON\n",
      "Anienis GROUP\n",
      "Tiberi GROUP\n",
      "Sabini PERSON\n",
      "Romam LOCATION\n",
      "Sabinum PERSON\n",
      "Sabini PERSON\n",
      "Collatinum GROUP\n",
      "dederetis?\"—\"Sumus LOCATION\n",
      "\"—\"Deditisne PERSON\n",
      "Collatinum GROUP\n",
      "Romani GROUP\n",
      "Sabino PERSON\n",
      "Romam LOCATION\n",
      "Cameria GROUP\n",
      "Ameriola GROUP\n",
      "Medullia GROUP\n",
      "Sabino PERSON\n",
      "Sabino PERSON\n",
      "Corniculo GROUP\n",
      "Prisci PERSON\n",
      "Tarquini GROUP\n",
      "Romulus PERSON\n",
      "Romani GROUP\n",
      "Primo PERSON\n",
      "Tarquini GROUP\n",
      "Lucio PERSON\n",
      "Etruscis GROUP\n",
      "Romam GROUP\n",
      "incidebat—[fiebat PERSON\n",
      "Romani GROUP\n",
      "Fabius PERSON\n",
      "Romani GROUP\n",
      "Romam LOCATION\n",
      "Romam LOCATION\n",
      "Sabinum PERSON\n",
      "L. PERSON\n",
      "Prisci PERSON\n",
      "Tarquini GROUP\n",
      "Romani GROUP\n",
      "Prisci PERSON\n",
      "Tarquini GROUP\n",
      "Facesse PERSON\n",
      "Tarquinios PERSON\n",
      "Tarquini GROUP\n",
      "Urbium GROUP\n",
      "Foedum GROUP\n",
      "Ser. PERSON\n",
      "L. PERSON\n",
      "Tarquini GROUP\n",
      "Aricia GROUP\n",
      "Superbo PERSON\n",
      "Tarquini GROUP\n",
      "Romani GROUP\n",
      "Romani GROUP\n",
      "L. PERSON\n",
      "Tarquini PERSON\n",
      "Hernicos GROUP\n",
      "Romam LOCATION\n",
      "Romam LOCATION\n",
      "Aequorum GROUP\n",
      "Tarquinios PERSON\n",
      "Fabio PERSON\n",
      "Intentus GROUP\n",
      "Delphos PERSON\n",
      "Titus PERSON\n",
      "L. PERSON\n",
      "Brutus PERSON\n",
      "Romani GROUP\n",
      "Delphos PERSON\n",
      "Romam LOCATION\n",
      "Brutus PERSON\n",
      "Romam LOCATION\n",
      "Romam LOCATION\n",
      "Romam LOCATION\n",
      "P. PERSON\n",
      "Valerio PERSON\n",
      "L. PERSON\n",
      "Bruto PERSON\n",
      "Romam LOCATION\n",
      "Collatine GROUP\n",
      "Cultrum GROUP\n",
      "Brutus PERSON\n",
      "L. PERSON\n",
      "Tarquinium PERSON\n",
      "Cultrum GROUP\n",
      "Valerio PERSON\n",
      "Brutus PERSON\n",
      "Romanos GROUP\n",
      "Bruto PERSON\n",
      "Romam LOCATION\n",
      "Brutus PERSON\n",
      "Tarquini GROUP\n",
      "Romanos GROUP\n",
      "L. PERSON\n",
      "Romam LOCATION\n",
      "Brutus PERSON\n",
      "Brutus PERSON\n",
      "Romam LOCATION\n",
      "L. PERSON\n",
      "Superbus PERSON\n",
      "L. PERSON\n",
      "Brutus PERSON\n",
      "L. PERSON\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-orientation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
