{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "offshore-reform",
   "metadata": {},
   "source": [
    "# Text Analysis with Ancient and Medieval Languages<br><br>Day 03:<br>Solving an NER Problem from Beginning to End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-cleanup",
   "metadata": {},
   "source": [
    "<center>Dr. William Mattingly<br>\n",
    "TAP Institute with JSTOR</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indoor-network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.20.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (8.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (54.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.3)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\wma22\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-basic",
   "metadata": {},
   "source": [
    "## Structure of Today"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-settlement",
   "metadata": {},
   "source": [
    "We have been given a task to develop a named entity recognition (NER) model for Latin. The problem: no NER model exists.\n",
    "\n",
    "In this notebook we will be solving this problem from beginning to end. In this scenario, no training data exists. No lemmatizer exists. No POS tagger exists. And no NER model exists. In other words, we need to start from the ground up. Fortunately, we have access to two different sources of information: raw text (TheLatinLibrary) and some structured tabular data about Latin names (Wikipedia) and some tabular data about places (Columbia's Orblata). With these limited resources, we will solve our problem, or at least have a base-line model for improvement in the future.\n",
    "\n",
    "Our workflow moving forward will be something like this:<br>\n",
    "1) Acquire data for constructing a list of Latin personal names, places, and groups.<br>\n",
    "2) Find words that appear in both lists and remove them to insure no false positives are matched, such as Romani which can be a PERSON or GROUP.<br>\n",
    "3) Decline all words in each list and store all these variant forms in separate files.<br>\n",
    "4) Create an EntityRuler in spaCy, or a rules-based approach with these declined forms<br>\n",
    "5) Use that EntityRuler to pass over a text. In our case, Caesar's Gallic War and use the output of the EntityRuler to generate a training set for a machine learning NER model.<br>\n",
    "6) Train base-line NER model<br>\n",
    "7) Use that base-line NER model to then help automate the cultivation of a domain-expert validated training set.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-office",
   "metadata": {},
   "source": [
    "## Part One: Grabbing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-newcastle",
   "metadata": {},
   "source": [
    "To keep this notebook a little cleaner, I have provided two other notebooks in this repo: wiki_scrape.ipynb and decline_latin.ipynb. We will be turning to these now and discussing how to webscrape and decline Latin words in Python. The need to decline Latin words stems from the fact that Latin is highly inflected and in this scenario, we do not have a lemmatizer, meaning we cannot simply find the roots of the word prior to passing the data to our NER model. Further, we cannot simply extract all proper nouns from a text, because we do not have a POS tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-vegetarian",
   "metadata": {},
   "source": [
    "## Part Two: Eliminating Potential False Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-robert",
   "metadata": {},
   "source": [
    "Discussion outside of notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-oasis",
   "metadata": {},
   "source": [
    "## Part Three: Declining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-funeral",
   "metadata": {},
   "source": [
    "See the notebook decline_latin.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-pizza",
   "metadata": {},
   "source": [
    "## Part Four: Create an EntityRuler in spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constant-engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amino-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interested-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gernating rules\n",
    "def generate_ruler(patterns, name):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "    ruler.add_patterns(patterns)\n",
    "    ruler.to_disk(f\"models/{name}_ent_ruler/entity_ruler/patterns.jsonl\") \n",
    "    nlp.to_disk(f\"models/{name}_ent_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "duplicate-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(file, type):\n",
    "    data = load_data(file)\n",
    "    patterns = []\n",
    "    for item in data:\n",
    "        pattern = {\n",
    "                    \"label\": type,\n",
    "                    \"pattern\": item\n",
    "                    }\n",
    "        patterns.append(pattern)\n",
    "    return (patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spread-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ent_ruler(ruler, corpus):\n",
    "    nlp = spacy.load(ruler)\n",
    "    with open (corpus, \"r\", encoding=\"utf-8\") as f:\n",
    "        corpus = f.read()\n",
    "    with open (\"temp/results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        doc = nlp(corpus)\n",
    "        for ent in doc.ents:\n",
    "            f.write(f\"{ent.text}, {ent.label_}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compliant-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_patterns = create_training_data(\"latin_data/all_names_declined.json\", \"PERSON\")\n",
    "groups_patterns = create_training_data(\"latin_data/groups_declined.json\", \"GROUP\")\n",
    "places_patterns = create_training_data(\"latin_data/places_declined.json\", \"LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caring-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patterns = person_patterns+groups_patterns+places_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prepared-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ruler(all_patterns, \"latin_loc_per_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "worldwide-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ent_ruler(\"models/latin_loc_per_group_ent_ruler\", \"latin_data/corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-flashing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-garden",
   "metadata": {},
   "source": [
    "## Part Five: Use the EntityRuler to Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "convertible-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_set(corpus, ent_ruler_model, output_file, prodigy=False):\n",
    "    nlp=spacy.load(ent_ruler_model)\n",
    "    TRAIN_DATA = []\n",
    "    with open (corpus, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "        segments = data.split(\"\\n\")\n",
    "        for segment in segments:\n",
    "            segment = segment.strip()\n",
    "            doc = nlp(segment)\n",
    "            entities = []\n",
    "            for ent in doc.ents:\n",
    "                if prodigy==True:\n",
    "                    entities.append({\"start\":ent.start_char, \"end\": ent.end_char,  \"label\": ent.label_, \"text\": ent.text})\n",
    "                    pass\n",
    "                else:\n",
    "                    entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "            if len(entities) > 0:\n",
    "                if prodigy==True:\n",
    "                    TRAIN_DATA.append({\"text\": segment, \"spans\": entities})\n",
    "                else:\n",
    "                    TRAIN_DATA.append([segment, {\"entities\": entities}])\n",
    "    print (len(TRAIN_DATA))\n",
    "    with open (output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(TRAIN_DATA, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "overhead-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n"
     ]
    }
   ],
   "source": [
    "create_training_set(\"latin_data/corpus.txt\", \"models/latin_loc_per_group_ent_ruler\", \"training_data/training_set_spacy.json\", prodigy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tutorial-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "changing-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = load_data(\"training_data/training_set_spacy.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "certified-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[3] His rebus adducti et auctoritate Orgetorigis permoti constituerunt ea quae ad proficiscendum pertinerent comparare, iumentorum et carrorum quam maximum numerum coemere, sementes quam maximas facere, ut in itinere copia frumenti suppeteret, cum proximis civitatibus pacem et amicitiam confirmare. Ad eas res conficiendas biennium sibi satis esse duxerunt; in tertium annum profectionem lege confirmant. Ad eas res conficiendas Orgetorix deligitur. Is sibi legationem ad civitates suscipit. In eo itinere persuadet Castico, Catamantaloedis filio, Sequano, cuius pater regnum in Sequanis multos annos obtinuerat et a senatu populi Romani amicus appellatus erat, ut regnum in civitate sua occuparet, quod pater ante habuerit; itemque Dumnorigi Haeduo, fratri Diviciaci, qui eo tempore principatum in civitate obtinebat ac maxime plebi acceptus erat, ut idem conaretur persuadet eique filiam suam in matrimonium dat. Perfacile factu esse illis probat conata perficere, propterea quod ipse suae civitatis imperium obtenturus esset: non esse dubium quin totius Galliae plurimum Helvetii possent; se suis copiis suoque exercitu illis regna conciliaturum confirmat. Hac oratione adducti inter se fidem et ius iurandum dant et regno occupato per tres potentissimos ac firmissimos populos totius Galliae sese potiri posse sperant.', {'entities': [[580, 588, 'GROUP'], [632, 638, 'GROUP'], [1075, 1083, 'GROUP']]}]\n"
     ]
    }
   ],
   "source": [
    "print (all_docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "photographic-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = all_docs[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "injured-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_docs = all_docs[200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-sussex",
   "metadata": {},
   "source": [
    "## Part Six: Train the Base-Line NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sacred-furniture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 620.32it/s]\n"
     ]
    }
   ],
   "source": [
    "train_db = DocBin()\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.blank(\"en\")\n",
    "for text, annot in tqdm(train_docs):\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            pass\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    train_db.add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tamil-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 188/188 [00:00<00:00, 587.24it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_db = DocBin()\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.blank(\"en\")\n",
    "for text, annot in tqdm(valid_docs):\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            pass\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    train_db.add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "million-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db.to_disk(\"./training_data/train_hs.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sudden-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_db.to_disk(\"./training_data/valid_hs.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "absolute-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-02 07:10:26.041561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "honest-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     81.36    0.00    0.00    0.00    0.00\n",
      "  0     200         53.84   2049.80    0.00    0.00    0.00    0.00\n",
      "  1     400         68.93    486.92    0.00    0.00    0.00    0.00\n",
      "  1     600         82.93    208.14    0.00    0.00    0.00    0.00\n",
      "  2     800         81.99    168.52    0.00    0.00    0.00    0.00\n",
      "  2    1000         84.50     95.88    0.00    0.00    0.00    0.00\n",
      "  3    1200        104.29     93.00    0.00    0.00    0.00    0.00\n",
      "  4    1400         81.09     67.93    0.00    0.00    0.00    0.00\n",
      "  5    1600         87.12     48.55    0.00    0.00    0.00    0.00\n",
      "[+] Saved pipeline to output directory\n",
      "output\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-02 07:10:30.351400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
      "[2021-07-02 07:10:33,248] [INFO] Set up nlp object from config\n",
      "[2021-07-02 07:10:33,254] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-07-02 07:10:33,257] [INFO] Created vocabulary\n",
      "[2021-07-02 07:10:33,257] [INFO] Finished initializing nlp object\n",
      "[2021-07-02 07:10:34,376] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fifty-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "colonial-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"latin_data/livy_01.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "suburban-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "narrow-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paphlagonia GROUP\n",
      "Pylaemene GROUP\n",
      "Troiam GROUP\n",
      "Troiano GROUP\n",
      "Veneti GROUP\n",
      "Macedoniam GROUP\n",
      "Laurentem GROUP\n",
      "Troiani GROUP\n",
      "Aboriginesque PERSON\n",
      "Latinum LOCATION\n",
      "Aeneam GROUP\n",
      "Veneris GROUP\n",
      "Ascanium GROUP\n",
      "Aborigines GROUP\n",
      "Aborigines GROUP\n",
      "Rutulique GROUP\n",
      "Etruscorum PERSON\n",
      "Rutulis GROUP\n",
      "Latinos GROUP\n",
      "Aborigines GROUP\n",
      "Aeneam GROUP\n",
      "Aeneas GROUP\n",
      "Siculum GROUP\n",
      "Iovem GROUP\n",
      "Latina PERSON\n",
      "Albam GROUP\n",
      "Etruscis LOCATION\n",
      "Etruscis LOCATION\n",
      "Silvius GROUP\n",
      "Aeneam GROUP\n",
      "Silvium GROUP\n",
      "Silvium GROUP\n",
      "Capys GROUP\n",
      "Capeto PERSON\n",
      "Albulae GROUP\n",
      "Silvius GROUP\n",
      "Amulium GROUP\n",
      "Numitori GROUP\n",
      "— PERSON\n",
      "— PERSON\n",
      "Lupercal GROUP\n",
      "Pallantium GROUP\n",
      "Arcadia LOCATION\n",
      "Lycaeum PERSON\n",
      "Romani GROUP\n",
      "Numitoris GROUP\n",
      "Numitori GROUP\n",
      "Remus PERSON\n",
      "Numitori GROUP\n",
      "Remus PERSON\n",
      "Numitori GROUP\n",
      "Remumque GROUP\n",
      "Albanorum GROUP\n",
      "Albam GROUP\n",
      "Remus PERSON\n",
      "Aventinum PERSON\n",
      "Priori GROUP\n",
      "Remus PERSON\n",
      "Herculi GROUP\n",
      "Evandro LOCATION\n",
      "Peloponneso GROUP\n",
      "Italiam LOCATION\n",
      "Herculi GROUP\n",
      "Pinariis GROUP\n",
      "Rebus GROUP\n",
      "Etruscis LOCATION\n",
      "Neptuno GROUP\n",
      "Romanam PERSON\n",
      "T. PERSON\n",
      "Crustuminique PERSON\n",
      "Tatius PERSON\n",
      "Sabinique PERSON\n",
      "Romani GROUP\n",
      "Romanos GROUP\n",
      "Crustuminos GROUP\n",
      "Romam LOCATION\n",
      "Sabinis PERSON\n",
      "Sabini PERSON\n",
      "Sabini PERSON\n",
      "Romani GROUP\n",
      "Sabinis PERSON\n",
      "Mettius PERSON\n",
      "Romanis GROUP\n",
      "Romanam PERSON\n",
      "Palati GROUP\n",
      "Sabini PERSON\n",
      "Romanis GROUP\n",
      "Statori GROUP\n",
      "Romani GROUP\n",
      "Romani GROUP\n",
      "Mettius PERSON\n",
      "Sabinis PERSON\n",
      "Romanos GROUP\n",
      "Palati GROUP\n",
      "Mettius GROUP\n",
      "Pulsum LOCATION\n",
      "Romani GROUP\n",
      "Sabinos GROUP\n",
      "Mettius GROUP\n",
      "Sabinos GROUP\n",
      "Romani GROUP\n",
      "Romam LOCATION\n",
      "Sabinis PERSON\n",
      "Sabinas GROUP\n",
      "T. PERSON\n",
      "Tatio PERSON\n",
      "Lucerum GROUP\n",
      "Laurentium GROUP\n",
      "Romam LOCATION\n",
      "Excitus PERSON\n",
      "Fidenis GROUP\n",
      "Romani GROUP\n",
      "Romanos GROUP\n",
      "Romam LOCATION\n",
      "Celeres PERSON\n",
      "Proculus PERSON\n",
      "Romanis GROUP\n",
      "Romanis GROUP\n",
      "Romuli GROUP\n",
      "Sabinis PERSON\n",
      "Romani GROUP\n",
      "Numae PERSON\n",
      "Sabinis PERSON\n",
      "Samium GROUP\n",
      "Tullio GROUP\n",
      "Sabinos GROUP\n",
      "Numae PERSON\n",
      "Romani GROUP\n",
      "Sabinos GROUP\n",
      "Numae PERSON\n",
      "Numae PERSON\n",
      "Numae PERSON\n",
      "T. PERSON\n",
      "Actiacum PERSON\n",
      "Caesare PERSON\n",
      "Augusto PERSON\n",
      "Clauso GROUP\n",
      "Egeria PERSON\n",
      "Romuli GROUP\n",
      "Numae PERSON\n",
      "Quirino GROUP\n",
      "Marci GROUP\n",
      "Iovi PERSON\n",
      "Elicio PERSON\n",
      "Aventino GROUP\n",
      "Egeria PERSON\n",
      "Numae PERSON\n",
      "Tullum PERSON\n",
      "Sabinos GROUP\n",
      "Romani GROUP\n",
      "Albano GROUP\n",
      "Gaius PERSON\n",
      "Albanis GROUP\n",
      "Tullo PERSON\n",
      "Romani GROUP\n",
      "Tullo PERSON\n",
      "Tullo LOCATION\n",
      "Lavinio GROUP\n",
      "Albanorum GROUP\n",
      "Romani GROUP\n",
      "Albanus GROUP\n",
      "Mettium GROUP\n",
      "Mettium GROUP\n",
      "Ducit GROUP\n",
      "Tullo LOCATION\n",
      "Romanam PERSON\n",
      "Albanus GROUP\n",
      "Memor GROUP\n",
      "Tullo PERSON\n",
      "Horatios PERSON\n",
      "Horatii PERSON\n",
      "Romanos GROUP\n",
      "Romanos GROUP\n",
      "Tullum PERSON\n",
      "Romani GROUP\n",
      "Romani GROUP\n",
      "M. PERSON\n",
      "Valerius PERSON\n",
      "Albanus GROUP\n",
      "Romani GROUP\n",
      "Albanis GROUP\n",
      "Albanus GROUP\n",
      "Albanus GROUP\n",
      "Romani GROUP\n",
      "— GROUP\n",
      "Romani GROUP\n",
      "Albam GROUP\n",
      "Romam LOCATION\n",
      "Princeps PERSON\n",
      "Curiatiis LOCATION\n",
      "Capenam GROUP\n",
      "Horatio GROUP\n",
      "Tullo PERSON\n",
      "P. PERSON\n",
      "Horatio PERSON\n",
      "Horatia PERSON\n",
      "Huncine PERSON\n",
      "Albanorum GROUP\n",
      "Horatiae GROUP\n",
      "Albanorum GROUP\n",
      "Fidenas PERSON\n",
      "Fidenatium GROUP\n",
      "Consilium GROUP\n",
      "Romanis GROUP\n",
      "Pallori GROUP\n",
      "Fidenatium GROUP\n",
      "Romanorum GROUP\n",
      "Fidenatium GROUP\n",
      "Romani GROUP\n",
      "Albanorum GROUP\n",
      "Fidenatium GROUP\n",
      "Mettius PERSON\n",
      "Romanis GROUP\n",
      "Romani GROUP\n",
      "Albanorum GROUP\n",
      "Mettius GROUP\n",
      "Mettius GROUP\n",
      "Romani GROUP\n",
      "Mettium GROUP\n",
      "Romam LOCATION\n",
      "Fufeti GROUP\n",
      "Mettium GROUP\n",
      "Romanos GROUP\n",
      "Albam GROUP\n",
      "Romam LOCATION\n",
      "Albanis GROUP\n",
      "Caelius GROUP\n",
      "Albanorum GROUP\n",
      "Iulios GROUP\n",
      "Quinctios GROUP\n",
      "Geganios GROUP\n",
      "Albanis GROUP\n",
      "Romanos GROUP\n",
      "Sabini PERSON\n",
      "Sabini PERSON\n",
      "Romanam PERSON\n",
      "Etruscorum PERSON\n",
      "Sabinum PERSON\n",
      "Devictis PERSON\n",
      "Sabinis PERSON\n",
      "Romanis GROUP\n",
      "Numae PERSON\n",
      "Iovi PERSON\n",
      "Elicio PERSON\n",
      "Mortuo GROUP\n",
      "Numae PERSON\n",
      "Ancus PERSON\n",
      "Tullo PERSON\n",
      "Romanis GROUP\n",
      "Numae PERSON\n",
      "Romuli GROUP\n",
      "Tullo PERSON\n",
      "Numae PERSON\n",
      "est—\"Audi GROUP\n",
      "Romani GROUP\n",
      "Iovem PERSON\n",
      "Quirine PERSON\n",
      "Romam LOCATION\n",
      "Romani GROUP\n",
      "Prisci PERSON\n",
      "Priscis PERSON\n",
      "Romani GROUP\n",
      "Priscis PERSON\n",
      "Priscis GROUP\n",
      "Romanam PERSON\n",
      "Romam LOCATION\n",
      "Romanorum GROUP\n",
      "Sabini PERSON\n",
      "Aventinum GROUP\n",
      "Romanis GROUP\n",
      "Romanis GROUP\n",
      "Ancus GROUP\n",
      "Romam LOCATION\n",
      "Palatio PERSON\n",
      "Aventinum PERSON\n",
      "Murciae PERSON\n",
      "Tiberi GROUP\n",
      "Tiberis PERSON\n",
      "Romam LOCATION\n",
      "Etruscis LOCATION\n",
      "Lucumonem PERSON\n",
      "Sabinum PERSON\n",
      "Numae PERSON\n",
      "Romam LOCATION\n",
      "L. PERSON\n",
      "Romanis GROUP\n",
      "Romam LOCATION\n",
      "Romanos GROUP\n",
      "Bellum PERSON\n",
      "Romani GROUP\n",
      "Sabinum PERSON\n",
      "Romanis GROUP\n",
      "Navius PERSON\n",
      "Sabinis PERSON\n",
      "Anienis GROUP\n",
      "Sabinis PERSON\n",
      "Tiberi GROUP\n",
      "Sabinas GROUP\n",
      "Sabini PERSON\n",
      "Romam LOCATION\n",
      "Volcano GROUP\n",
      "Sabinum PERSON\n",
      "Sabini PERSON\n",
      "Sabinis PERSON\n",
      "— PERSON\n",
      "Collatino GROUP\n",
      "Collatinum GROUP\n",
      "Collatinum GROUP\n",
      "Romani GROUP\n",
      "Sabino PERSON\n",
      "Romam LOCATION\n",
      "Priscis PERSON\n",
      "Cameria GROUP\n",
      "Ameriola GROUP\n",
      "Medullia GROUP\n",
      "Nomentum GROUP\n",
      "Priscis GROUP\n",
      "Sabino PERSON\n",
      "Sabino PERSON\n",
      "Tullio GROUP\n",
      "Corniculo GROUP\n",
      "Ser. PERSON\n",
      "Duodequadragesimo GROUP\n",
      "Ser. PERSON\n",
      "Romani GROUP\n",
      "Servium GROUP\n",
      "Primo PERSON\n",
      "Clamor PERSON\n",
      "Servi GROUP\n",
      "Iovis PERSON\n",
      "Statoris PERSON\n",
      "Ser. PERSON\n",
      "Tullio GROUP\n",
      "Servi GROUP\n",
      "Suessam PERSON\n",
      "Tarquini GROUP\n",
      "Lucio PERSON\n",
      "Etruscis GROUP\n",
      "Romam LOCATION\n",
      "Servium GROUP\n",
      "Ser. PERSON\n",
      "Tullio GROUP\n",
      "Censu GROUP\n",
      "Romani GROUP\n",
      "Fabius PERSON\n",
      "Romani GROUP\n",
      "Dianae GROUP\n",
      "Dianae GROUP\n",
      "Romam LOCATION\n",
      "Sabinis PERSON\n",
      "Sabinis GROUP\n",
      "Dianae GROUP\n",
      "Dianae GROUP\n",
      "Dianae GROUP\n",
      "Romam LOCATION\n",
      "Dianae GROUP\n",
      "Sabinum PERSON\n",
      "Dianae GROUP\n",
      "Religione GROUP\n",
      "Dianae GROUP\n",
      "Servi GROUP\n",
      "Tullia GROUP\n",
      "L. PERSON\n",
      "— PERSON\n",
      "Prisci PERSON\n",
      "Tarquini GROUP\n",
      "Romani GROUP\n",
      "Servi GROUP\n",
      "Tullia GROUP\n",
      "Tullia GROUP\n",
      "Corintho GROUP\n",
      "Tarquinios GROUP\n",
      "Corinthum GROUP\n",
      "Servium GROUP\n",
      "Servium GROUP\n",
      "— PERSON\n",
      "Sceleratum PERSON\n",
      "Tullia PERSON\n",
      "Ser. PERSON\n",
      "L. PERSON\n",
      "Superbo GROUP\n",
      "Servi GROUP\n",
      "Ulixe GROUP\n",
      "Tarquini GROUP\n",
      "Ferentinae GROUP\n",
      "Aricia GROUP\n",
      "Superbo GROUP\n",
      "Latinos GROUP\n",
      "Latinos GROUP\n",
      "Tarquini GROUP\n",
      "Tullo PERSON\n",
      "Romani GROUP\n",
      "Ferentinae GROUP\n",
      "Romani GROUP\n",
      "Suessamque PERSON\n",
      "L. PERSON\n",
      "Tarquini PERSON\n",
      "Latium GROUP\n",
      "Hernicos GROUP\n",
      "Romam LOCATION\n",
      "Romam LOCATION\n",
      "Aequorum GROUP\n",
      "Tarquinios GROUP\n",
      "Termini GROUP\n",
      "Fabio PERSON\n",
      "Pisoni GROUP\n",
      "Circeiosque PERSON\n",
      "Graeciam GROUP\n",
      "Titus PERSON\n",
      "L. PERSON\n",
      "Brutus GROUP\n",
      "Tarquinia GROUP\n",
      "Romani GROUP\n",
      "Delphos PERSON\n",
      "Romam LOCATION\n",
      "Romam LOCATION\n",
      "Rutulos PERSON\n",
      "Romam LOCATION\n",
      "Tarquiniique PERSON\n",
      "Lucretiae GROUP\n",
      "Collatino GROUP\n",
      "Romam LOCATION\n",
      "P. PERSON\n",
      "Valerio PERSON\n",
      "L. PERSON\n",
      "Iunio PERSON\n",
      "Bruto PERSON\n",
      "Romam LOCATION\n",
      "Lucretiae GROUP\n",
      "Lucretiae GROUP\n",
      "L. PERSON\n",
      "Collatino GROUP\n",
      "Valerio PERSON\n",
      "Brutum PERSON\n",
      "Lucretiae GROUP\n",
      "Brutus GROUP\n",
      "Romanos GROUP\n",
      "Bruto PERSON\n",
      "Romam LOCATION\n",
      "Lucretiae GROUP\n",
      "Romanos GROUP\n",
      "Ser. PERSON\n",
      "L. PERSON\n",
      "Romam LOCATION\n",
      "Brutus GROUP\n",
      "Brutus GROUP\n",
      "Romam LOCATION\n",
      "L. PERSON\n",
      "Tarquinius PERSON\n",
      "Ser. PERSON\n",
      "L. PERSON\n",
      "L. PERSON\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-adams",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
